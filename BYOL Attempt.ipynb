{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.models\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x174a10d04b0>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    \"\"\"blur a single image on CPU\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        radias = kernel_size // 2\n",
    "        kernel_size = radias * 2 + 1\n",
    "        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.k = kernel_size\n",
    "        self.r = radias\n",
    "\n",
    "        self.blur = nn.Sequential(\n",
    "            nn.ReflectionPad2d(radias),\n",
    "            self.blur_h,\n",
    "            self.blur_v\n",
    "        )\n",
    "\n",
    "        self.pil_to_tensor = transforms.ToTensor()\n",
    "        self.tensor_to_pil = transforms.ToPILImage()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.pil_to_tensor(img).unsqueeze(0)\n",
    "\n",
    "        sigma = np.random.uniform(0.1, 2.0)\n",
    "        x = np.arange(-self.r, self.r + 1)\n",
    "        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
    "        x = x / x.sum()\n",
    "        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
    "\n",
    "        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
    "        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img = self.blur(img)\n",
    "            img = img.squeeze()\n",
    "\n",
    "        img = self.tensor_to_pil(img)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transforms(Input_Dim,S=1):\n",
    "    Color_Jitter = transforms.ColorJitter(0.8*S,0.8*S,0.8*S,0.2*S)\n",
    "    Data_Transforms = transforms.Compose([transforms.RandomResizedCrop(size=Input_Dim[0]),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.RandomApply([Color_Jitter],p=0.75),\n",
    "                                         transforms.RandomGrayscale(p=0.2),\n",
    "                                         GaussianBlur(int(0.1*Input_Dim[0])),\n",
    "                                         transforms.ToTensor(),\n",
    "                                        ])\n",
    "    return Data_Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiViewDataInjector(object):\n",
    "    def __init__(self,Transforms):\n",
    "        self.transforms = Transforms\n",
    "    def __call__(self,Sample,*Consistent_Flip):\n",
    "        if Consistent_Flip:\n",
    "            Sample  =  torchvision.transforms.RandomHorizontalFlip()\n",
    "        Output = [transforms(Sample) for transforms in self.transforms]\n",
    "        return Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Base(nn.Module):\n",
    "    def __init__(self,Inp,Hidden,Projection):\n",
    "        super(MLP_Base,self).__init__()\n",
    "        self.Linear1 = nn.Linear(Inp,Hidden)\n",
    "        self.BatchNorm = nn.BatchNorm1d(Hidden)\n",
    "        self.Linear2 = nn.Linear(Hidden,Projection)\n",
    "    def forward(self,Input):\n",
    "        Linear_Inp = torch.relu(self.BatchNorm(self.Linear1(Input)))\n",
    "        Linear_Out = self.Linear2(Linear_Inp)\n",
    "        return Linear_Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkeletonNet(nn.Module):\n",
    "    def __init__(self,Hid,Proj):\n",
    "        super(SkeletonNet,self).__init__()\n",
    "        Resnet = torchvision.models.resnet18(pretrained=False)\n",
    "        self.Encoder = torch.nn.Sequential(*list(Resnet.children())[:-1])\n",
    "        self.Proj = MLP_Base(Resnet.fc.in_features,Hid,Proj)\n",
    "    def forward(self,Input):\n",
    "        Enc_Out = self.Encoder(Input)\n",
    "        Enc_Out = Enc_Out.view(Enc_Out.size(0),Enc_Out.size(1))\n",
    "        Final = self.Proj(Enc_Out)\n",
    "        return Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL:\n",
    "    def __init__(self,Online_Net,Target_Net,Predictor,Optim,Params):\n",
    "        self.Online_Net = Online_Net\n",
    "        self.Target_Net = Target_Net\n",
    "        self.Predictor  = Predictor\n",
    "        self.Optim      = Optim\n",
    "        self.Device     = Params['Device']\n",
    "        self.Epochs     = Params['Epochs']\n",
    "        self.Moment        = Params['M']\n",
    "        self.Batch_Size = Params['Batch_Size']\n",
    "        self.Save_Path = 'G:\\Work Related\\BYOL\\Models/BYOL.pth'\n",
    "    @torch.no_grad()\n",
    "    def Update_Target_Params(self):\n",
    "        for Param_Online,Param_Target in zip(self.Online_Net.parameters(),self.Target_Net.parameters()):\n",
    "            Param_Target = Param_Target.data *self.Moment + Param_Online.data*(1-self.Moment)\n",
    "    @staticmethod          \n",
    "    def Loss(Rep1,Rep2):\n",
    "        Norm_Rep1 = F.normalize(Rep1,dim=-1,p=2) #L2-Normalized Rep One\n",
    "        Norm_Rep2 = F.normalize(Rep2,dim=-1,p=2) #L2 Normalized Rep Two\n",
    "        Loss = -2 * (Norm_Rep1*Norm_Rep2).sum(dim=-1)\n",
    "        return Loss \n",
    "    def Init_Target_Network(self):\n",
    "        for Param_Online,Param_Target in zip(self.Online_Net.parameters(),self.Target_Net.parameters()):\n",
    "            Param_Target.data.copy_(Param_Online.data) #Init Target with Param_Online\n",
    "            Param_Target.requires_grad = False\n",
    "    def TrainLoop(self,View1,View2):\n",
    "        Pred1 = self.Predictor(self.Online_Net(View1))\n",
    "        Pred2 = self.Predictor(self.Online_Net(View2))\n",
    "        with torch.no_grad():\n",
    "            Target2 = self.Target_Net(View1)\n",
    "            Target1 = self.Target_Net(View2)\n",
    "        Loss_Calc = self.Loss(Pred1,Target1) + self.Loss(Pred2,Target2)\n",
    "        return Loss_Calc.mean()\n",
    "    def Train(self,Trainset):\n",
    "        TrainLoader = torch.utils.data.DataLoader(Trainset,batch_size=self.Batch_Size,drop_last=False,shuffle=True)\n",
    "        self.Init_Target_Network()\n",
    "        for Epoch in range(self.Epochs):\n",
    "            print(\"Epoch {}\".format(Epoch))\n",
    "            for (View_1,View_2),_ in tqdm(TrainLoader):\n",
    "                View_1 = View_1.to(self.Device)\n",
    "                View_2 = View_2.to(self.Device)\n",
    "                Loss = self.TrainLoop(View_1,View_2)\n",
    "                self.Optim.zero_grad()\n",
    "                Loss.backward()\n",
    "                self.Optim.step()\n",
    "                self.Update_Target_Params()\n",
    "            print(\"Epoch{} Loss:{} : \".format(Epoch,Loss.item()))\n",
    "        self.Save(self.Save_Path)\n",
    "    def Save(self,Save):\n",
    "        torch.save({'Online_Net':self.Online_Net.state_dict(),\n",
    "                    'Enc_Net':self.Online_Net.Encoder.state_dict(),\n",
    "                    'Target_Net':self.Target_Net.state_dict(),\n",
    "                    'Optim':self.Optim.state_dict()},Save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters = {'Epochs':50,'M':0.99,'Batch_Size':64,'Device':'cuda','Hidden':512,'Proj':128,'LR':0.03}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Transforms = Transforms((3,32,32))\n",
    "Dataset = datasets.CIFAR10('G:\\Work Related\\BYOL\\Dataset/',download=False,transform=MultiViewDataInjector([Data_Transforms,Data_Transforms]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "Online_Network = SkeletonNet(Parameters['Hidden'],Parameters['Proj'])\n",
    "Predictor = MLP_Base(Online_Network.Proj.Linear2.out_features,Parameters['Hidden'],Parameters['Proj'])\n",
    "Target_Network = SkeletonNet(Parameters['Hidden'],Parameters['Proj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Online_Network.to(Parameters['Device'])\n",
    "Predictor.to(Parameters['Device'])\n",
    "Target_Network.to(Parameters['Device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimizer = torch.optim.SGD(list(Online_Network.parameters())+list(Predictor.parameters()),lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainer = BYOL(Online_Network,Target_Network,Predictor,Optimizer,Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]\n",
      "  0%|                                                                                          | 0/782 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                  | 1/782 [00:01<21:58,  1.69s/it]\u001b[A\n",
      "  0%|▏                                                                                 | 2/782 [00:03<22:15,  1.71s/it]\u001b[A\n",
      "  0%|▎                                                                                 | 3/782 [00:05<22:30,  1.73s/it]\u001b[A\n",
      "  1%|▍                                                                                 | 4/782 [00:06<22:25,  1.73s/it]\u001b[A\n",
      "  1%|▌                                                                                 | 5/782 [00:08<22:36,  1.75s/it]\u001b[A\n",
      "  1%|▋                                                                                 | 6/782 [00:10<22:31,  1.74s/it]\u001b[A\n",
      "  1%|▋                                                                                 | 7/782 [00:12<22:38,  1.75s/it]\u001b[A\n",
      "  1%|▊                                                                                 | 8/782 [00:14<22:43,  1.76s/it]\u001b[A\n",
      "  1%|▉                                                                                 | 9/782 [00:15<22:36,  1.76s/it]\u001b[A\n",
      "  1%|█                                                                                | 10/782 [00:17<22:36,  1.76s/it]\u001b[A\n",
      "  1%|█▏                                                                               | 11/782 [00:19<22:38,  1.76s/it]\u001b[A\n",
      "  2%|█▏                                                                               | 12/782 [00:21<22:25,  1.75s/it]\u001b[A\n",
      "  2%|█▎                                                                               | 13/782 [00:22<22:34,  1.76s/it]\u001b[A\n",
      "  2%|█▍                                                                               | 14/782 [00:26<24:19,  1.90s/it]\u001b[A\n",
      "  0%|                                                                                           | 0/50 [00:26<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-30e9bd882832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mTrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-235-f8edcb957851>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self, Trainset)\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[1;31m#print(\"Regression Loss  :\",Loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpdate_Target_Params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\python\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\python\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "Trainer.Train(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
